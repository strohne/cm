# Übersicht über Skripte 

In diesem Kapitel werden unterschiedliche Varianten des Webscraping eingeführt, durch welches Inhalte von Webpages ausgelesen werden können. 
Den größten Lerneffekt erzielen Sie dabei, wenn Sie selbst direkt Daten über Webscraping miterheben. Zum Einstieg lohnt sich zunächst ein Blick 
in das Kapitel 5, in welchem in die Programmierung mit Python oder R eingeführt wird. Sie können Sie für eine Programmiersprache entscheiden und nachfolgend 
die entsprechenden Skripte auswählen.

Um die Erhebungsprozesse beim Webscraping bzw. Webcralwing mitgehen zu können, sind in diesem Ordner vorbereitet: 
- das Python-Skript **webscraping.py**  sowie das pendant für R **webscraping.R**, für klassisches Webscraping (Kapitel 7.1.1),
- das Python-Skript **webcrawling_selenium.py**  sowie das R-Skript **webcrawling_selenium.R** für Webscraping mittels Browserautomatisierung (Kapitel 7.1.2).

Wenn Sie Python über Jupyter Notebooks bedienen, können Sie für eine schrittweise Ausführung der Skripte, je den im Kapitel beschriebenen Codeblock in Zellen ihres Jupyter Notebooks kopieren. Alternativ können Sie diese Befehle auch aus den Python-Skripten kopieren.

*Hinweis:* Betreiber von Webseiten verändern diese von Zeit zu Zeit. Deswegen kann es sein, dass die Beispiele in den Skripten 
nicht mehr genauso funktionieren und es zu Fehlermeldungen kommt, wenn beispielsweise Elemente nicht gefunden werden können. In dem Kapitel wird je durch die Befehle durchgeführt. Sollten Sie deswegen irgendwo hängen, versuchen Sie diesen Schritt nachzuvollziehen und selbst anzupassen. 

# Nützliche Techniken zum Boilerplate Removal

https://medium.com/@mbatchkarov/a-benchmark-comparison-of-extraction-from-html-pages-98d7c1229f51

https://ujeebu.com/blog/how-to-extract-clean-text-from-html/

https://trafilatura.readthedocs.io/en/latest/ https://github.com/adbar/trafilatura

https://github.com/misja/python-boilerpipe

https://ws-dl.blogspot.com/2017/03/2017-03-20-survey-of-5-boilerplate.html

